# CI/CD Maintenance Playbook

**Date:** 2025-08-05  
**Version:** 1.0  
**Purpose:** Prevent regression and maintain CI/CD pipeline health

## üéØ Overview

This playbook provides step-by-step procedures for maintaining the CI/CD pipeline health and resolving common issues that may arise. Use this guide to diagnose problems, apply fixes, and prevent regressions.

---

## üö® Emergency Response Procedures

### Critical CI Failure (All workflows failing)

**Symptoms:**
- Multiple workflows showing red status
- Developers unable to merge PRs
- Build/deploy processes broken

**Immediate Actions:**
1. **Check Recent Changes**
   ```bash
   git log --oneline -10  # Review last 10 commits
   gh run list --limit 5  # Check recent workflow runs
   ```

2. **Identify Pattern**
   - Single commit causing issues? ‚Üí Consider revert
   - Environment changes? ‚Üí Check secrets/variables
   - Dependency updates? ‚Üí Check requirements files

3. **Quick Mitigation**
   ```bash
   # If specific commit identified
   git revert <commit-hash>
   git push origin main
   
   # If environment issue
   gh variable list  # Check GitHub variables
   gh secret list    # Check GitHub secrets
   ```

---

## üîç Diagnostic Procedures

### 1. Test Failures

#### API Test Crashes
**Symptoms:**
```bash
tests/test_api_*.py FAILED - ImportError/ValidationError
Session terminated early
```

**Diagnosis:**
```bash
# Check if defensive error handling is in place
grep -r "pytest.skip" tests/test_api_*.py

# Verify environment setup
grep -r "_setup_api_env" tests/conftest.py

# Test locally with CI conditions
CI_OFFLINE=1 pytest tests/test_api_auth.py --disable-socket -v
```

**Fix:**
```python
# Pattern that should be in all API tests:
def load_app(monkeypatch):
    monkeypatch.setenv("API_KEY", "test-key")
    monkeypatch.setenv("IP_WHITELIST", "")
    try:
        import agentic_index_api.server as srv
        module = importlib.reload(srv)
        return TestClient(module.app), module
    except Exception as e:
        pytest.skip(f"Could not load API server: {e}")
```

#### Coverage Threshold Failures
**Symptoms:**
```bash
Coverage X% (threshold Y%)
Coverage below threshold
```

**Diagnosis:**
```bash
# Check current coverage locally
pytest --cov=agentic_index_cli --cov-report=term-missing

# Check threshold alignment
grep -r "cov-fail-under" .github/workflows/ci.yml
grep -r "THRESHOLD" scripts/coverage_gate.py
grep -r "THRESHOLD" tests/test_coverage_gate.py
```

**Fix Options:**
1. **Increase Coverage** (preferred):
   - Add tests for uncovered code
   - Remove dead code

2. **Adjust Threshold** (if realistic):
   ```bash
   # Update all three locations consistently:
   # 1. .github/workflows/ci.yml
   pytest --cov-fail-under=XX
   
   # 2. scripts/coverage_gate.py  
   THRESHOLD = XX
   
   # 3. tests/test_coverage_gate.py
   # Update test expectations
   ```

### 2. Security Scan Failures

#### New Bandit Violations
**Symptoms:**
```bash
>> Issue: [BXXX:violation_type] Description
security-scan job FAILED
```

**Diagnosis:**
```bash
# Run bandit locally
bandit -r agentic_index_cli -f json

# Check current suppressions
cat .bandit
```

**Fix Options:**
1. **Fix the Issue** (preferred):
   - Address legitimate security concerns
   - Refactor problematic code

2. **Suppress False Positives**:
   ```yaml
   # Add to .bandit file with justification
   [bandit]
   skips = B101,B110,BXXX  # Add new code
   
   # Document why suppression is acceptable
   # BXXX: specific_violation - Justification here
   ```

### 3. Code Quality Issues

#### Black Formatting Failures
**Symptoms:**
```bash
would reformat file.py
Oh no! üí• üíî üí•
```

**Fix:**
```bash
# Format locally and commit
black agentic_index_cli tests scripts
git add -A
git commit -m "style: apply black formatting"
```

#### MyPy Type Errors
**Symptoms:**
```bash
file.py:line: error: Type annotation issue
```

**Fix:**
```bash
# Run mypy locally to see all errors
mypy agentic_index_cli/cli.py agentic_index_cli/enricher.py

# Fix type annotations or add type ignores where appropriate
```

---

## üõ†Ô∏è Preventive Maintenance

### Weekly Tasks

#### 1. Coverage Monitoring
```bash
# Generate and review coverage report
pytest --cov=agentic_index_cli --cov-report=html
open htmlcov/index.html

# Look for:
# - Declining coverage trends
# - Untested critical code paths
# - Files with <50% coverage
```

#### 2. Test Health Check
```bash
# Run full test suite locally
CI_OFFLINE=1 pytest --disable-socket -v

# Check for:
# - Increased skip counts
# - Slow tests (>10s each)
# - Flaky tests (intermittent failures)
```

#### 3. Security Review
```bash
# Run security scan locally
bandit -r agentic_index_cli

# Review suppressions in .bandit
# - Are they still justified?
# - Can any be removed?
```

### Monthly Tasks

#### 1. Dependency Updates
```bash
# Check for outdated dependencies
pip list --outdated

# Update and test
pip-compile requirements.in
pip-compile dev-requirements.in

# Run full test suite after updates
pytest
```

#### 2. Workflow Performance Analysis
```bash
# Review recent workflow run times
gh run list --limit 20

# Look for:
# - Increasing run times
# - Frequently failing workflows
# - Resource usage patterns
```

#### 3. Documentation Updates
- Review and update this playbook
- Update CI/CD improvement docs
- Check accuracy of troubleshooting guides

---

## üîß Common Fixes & Patterns

### Environment Variable Issues

**Problem:** Missing environment variables in CI
**Pattern:** 
```python
# Always provide defaults for test environments
class Settings(BaseSettings):
    API_KEY: str = os.getenv("API_KEY", "test-key")
    IP_WHITELIST: str = os.getenv("IP_WHITELIST", "")
```

### Test Fixture Synchronization

**Problem:** Outdated test fixtures causing failures
**Pattern:**
```bash
# Regular fixture updates (monthly)
cp data/repos.json tests/fixtures/data/repos.json
cp data/top100.md tests/fixtures/data/top100.md
cp README.md tests/fixtures/README_fixture.md
```

### Mock Configuration Issues

**Problem:** Incomplete API mocking
**Pattern:**
```python
# Always mock all HTTP calls your code makes
@responses.activate
def test_api_function():
    # Mock GET request
    responses.add(responses.GET, "https://api.example.com/search", json={"items": []})
    # Mock POST request  
    responses.add(responses.POST, "https://api.example.com/create", json={"id": 1})
```

---

## üìä Health Monitoring

### Key Metrics to Track

#### Workflow Success Rates
```bash
# Weekly calculation
total_runs=$(gh run list --limit 50 | wc -l)
successful_runs=$(gh run list --limit 50 | grep "success" | wc -l)
success_rate=$((successful_runs * 100 / total_runs))
echo "Success rate: ${success_rate}%"
```

#### Test Suite Health
```bash
# Track test counts over time
total_tests=$(pytest --collect-only -q | grep "tests collected" | cut -d' ' -f1)
echo "Total tests: $total_tests"

# Track coverage trends
current_coverage=$(pytest --cov=agentic_index_cli --cov-report=term | grep "TOTAL" | awk '{print $4}')
echo "Current coverage: $current_coverage"
```

#### Performance Metrics
```bash
# Average CI run time (last 10 runs)
gh run list --limit 10 --json duration | jq '.[] | .duration' | awk '{sum+=$1; count++} END {print "Average duration:", sum/count, "seconds"}'
```

### Alert Thresholds

- **Success Rate < 90%**: Investigate immediately
- **Coverage < 70%**: Review test additions needed
- **CI Runtime > 5 minutes**: Optimize slow tests
- **Security Violations > 0**: Address or document suppressions

---

## üöÄ Continuous Improvement

### Automation Opportunities

#### 1. Automated Fixture Updates
```yaml
# GitHub Action to sync fixtures weekly
name: Update Test Fixtures
on:
  schedule:
    - cron: '0 2 * * 1'  # Monday 2 AM
jobs:
  update-fixtures:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Update fixtures
        run: |
          cp data/repos.json tests/fixtures/data/repos.json
          cp README.md tests/fixtures/README_fixture.md
      - name: Create PR if changes
        # ... PR creation logic
```

#### 2. Coverage Threshold Auto-Adjustment
```python
# Enhancement to coverage_gate.py
def auto_adjust_threshold(current_coverage, threshold):
    if current_coverage > threshold + 5:
        new_threshold = min(90, (current_coverage // 5) * 5)
        return new_threshold
    return threshold
```

#### 3. Flaky Test Detection
```bash
# Script to identify flaky tests
#!/bin/bash
for i in {1..10}; do
  pytest --tb=no -q > run_$i.txt 2>&1
done
# Analyze which tests sometimes pass/fail
```

### Performance Optimizations

#### 1. Parallel Test Execution
```yaml
# Add to ci.yml for faster CI
- name: Run tests with coverage
  run: pytest -n auto --cov=agentic_index_cli --cov-report=xml
```

#### 2. Test Categorization
```python
# Mark slow tests
@pytest.mark.slow
def test_expensive_operation():
    pass

# Run in CI: pytest -m "not slow" for fast feedback
```

#### 3. Selective Test Running
```bash
# Only run tests for changed files
python scripts/selective_testing.py $(git diff --name-only HEAD~1)
```

---

## üìã Troubleshooting Checklist

When CI issues arise, work through this checklist:

### Initial Assessment
‚ñ° Check GitHub status page for service issues  
‚ñ° Review recent commits for obvious problems  
‚ñ° Verify no changes to secrets/environment variables  
‚ñ° Check if issue affects all workflows or specific ones  

### Test Failures
‚ñ° Can you reproduce locally with `CI_OFFLINE=1 pytest --disable-socket`?  
‚ñ° Are all API tests using defensive error handling pattern?  
‚ñ° Are test fixtures synchronized with current data?  
‚ñ° Are all external API calls properly mocked?  

### Security/Quality Issues
‚ñ° Run bandit locally - any new violations?  
‚ñ° Run black locally - any formatting issues?  
‚ñ° Run mypy locally - any type errors?  
‚ñ° Check .bandit file for missing suppressions  

### Coverage Issues
‚ñ° Check actual coverage vs. threshold settings  
‚ñ° Are thresholds aligned in ci.yml, coverage_gate.py, and tests?  
‚ñ° Any new untested code added recently?  

### Environment Issues
‚ñ° Are all required environment variables set in CI?  
‚ñ° Do configuration classes have appropriate defaults?  
‚ñ° Is pytest fixture setting up test environment correctly?  

---

## üìû Escalation Procedures

### When to Escalate
- Multiple developers blocked for >2 hours
- Security vulnerabilities in production code
- Data corruption or loss in CI artifacts
- Repeated failures of same type despite fixes

### Contact Information
- **CI/CD Owner**: Repository maintainer
- **Security Team**: For bandit/security issues
- **Infrastructure**: For GitHub Actions platform issues

### Documentation to Provide
1. Specific error messages and logs
2. Recent changes that might be related
3. Steps already attempted to resolve
4. Impact on development team

---

## üîÑ Playbook Maintenance

This playbook should be updated:
- **After each major CI incident** - Add new scenarios and fixes
- **Monthly** - Review accuracy and add new automation
- **After dependency updates** - Update commands and procedures
- **When team practices change** - Reflect new development workflows

**Last Updated:** 2025-08-05  
**Next Review Due:** 2025-09-05